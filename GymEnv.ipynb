{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "from itertools import product\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from agents.q_learner import Q_learner\n",
    "from utils.cartpole import CartPoleEnv\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = dict()\n",
    "args[\"BUFFER_SIZE\"] = int(500)  # replay buffer size\n",
    "args[\"BATCH_SIZE\"] = 32  # minibatch size\n",
    "args[\"GAMMA\"] = 0.95  # discount factor\n",
    "args[\"TAU\"] = 1e-3  # for soft update of target parameters\n",
    "args[\"LR\"] = 0.001  # learning rate\n",
    "args[\"UPDATE_EVERY\"] = 4  # how often to update the network\n",
    "\n",
    "env_name = 'CartPole-v1'\n",
    "\n",
    "def my_product(inp):\n",
    "    return (dict(zip(inp.keys(), values)) for values in product(*inp.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_dict_to_tuple(param):\n",
    "    param_list = []\n",
    "    if \"seed\" not in param.keys():\n",
    "        param_list += [0]\n",
    "    else:\n",
    "        param_list += [param[\"seed\"]]\n",
    "        \n",
    "    if \"length\" not in param.keys():\n",
    "        param_list += [0.5]\n",
    "    else:\n",
    "        param_list += [param[\"length\"]]\n",
    "        \n",
    "    if \"gravity\" not in param.keys():\n",
    "        param_list += [9.8]\n",
    "    else:\n",
    "        param_list += [param[\"gravity\"]]\n",
    "        \n",
    "    if \"force_mag\" not in param.keys():\n",
    "        param_list += [10.0]\n",
    "    else:\n",
    "        param_list += [param[\"force_mag\"]]\n",
    "    return tuple(param_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Task_Wrapper():\n",
    "    def __init__(self, env_name, params):\n",
    "        self.env_name = env_name\n",
    "        self.params = list(my_product(params))\n",
    "        self.current_param = 0\n",
    "        self.seed = seed\n",
    "        self.envs = []\n",
    "        \n",
    "    def next_task(self):\n",
    "        params = self.params[self.current_param]\n",
    "        params_tuple = transform_dict_to_tuple(params)\n",
    "        env = CartPoleEnv(**params)\n",
    "        env.seed(self.seed)\n",
    "        self.current_param+=1\n",
    "        self.envs.append({params_tuple : env})\n",
    "        return self.envs\n",
    "    \n",
    "    def get_env(self, index):\n",
    "        params = self.params[index]\n",
    "        env = CartPoleEnv(**params)\n",
    "        env.seed(self.seed)\n",
    "        return env \n",
    "\n",
    "class Queue():\n",
    "    def __init__(self, capacity):\n",
    "        self.capacity = capacity-1\n",
    "        self.queue = []\n",
    "        self.nb_elems = -1\n",
    "        \n",
    "    def add(self, elem):\n",
    "        if self.nb_elems == self.capacity:\n",
    "            self.pop()\n",
    "            self.add(elem)\n",
    "        else:\n",
    "            self.queue.append(elem)\n",
    "            self.nb_elems+=1\n",
    "    \n",
    "    def pop(self):        \n",
    "        self.nb_elems -=1\n",
    "        return self.queue.pop(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[7, 8, 9]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = [i for i in range(10)]\n",
    "x[-3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dqn(envs, agent = None, n_episodes=10000, max_t=1000, eps_start=1, eps_end=0.01, eps_decay=0.995):\n",
    "    scores_test = [Queue(20) for i in range(len(envs))]\n",
    "    scores = []                        \n",
    "    scores_window = deque(maxlen=100)  \n",
    "    eps = eps_start                    \n",
    "    env = list(envs[-1].values())[0]\n",
    "    for i_episode in range(1, n_episodes+1):\n",
    "        test_dqns(scores_test, envs, agent)\n",
    "\n",
    "        state = env.reset()\n",
    "        score = 0\n",
    "        for t in range(max_t):\n",
    "            action = agent.act(state, eps)\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "            agent.step(state, action, reward, next_state, done)\n",
    "            state = next_state\n",
    "            score += reward\n",
    "            if done:\n",
    "                break \n",
    "        scores_window.append(score)       \n",
    "        scores.append(score)              \n",
    "        eps = max(eps_end, eps_decay*eps)\n",
    "        \n",
    "        print('\\rEpisode {}\\tAverage Score: {:.2f}'.format(i_episode, np.mean(scores_window)), end=\"\")\n",
    "        if i_episode % 100 == 0:\n",
    "            print('\\rEpisode {}\\tAverage Score: {:.2f}'.format(i_episode, np.mean(scores_window)))\n",
    "        if np.mean(scores_window)>=200.0:\n",
    "            print('\\nEnvironment solved in {:d} episodes!\\tAverage Score: {:.2f}'.format(i_episode-100, np.mean(scores_window)))\n",
    "            torch.save(agent.qnetwork_local.state_dict(), 'models/checkpoints/checkpoint.pth')\n",
    "            break\n",
    "    scores_test_list = [np.array(scores_test[i].queue).mean() for i in range(len(scores_test)) ]\n",
    "    return scores, scores_test_list\n",
    "\n",
    "\n",
    "def test_dqns(scores_test, envs, agent, n_episodes = 10, max_t = 1000):\n",
    "    for i in range(len(envs)):\n",
    "        env_i = list(envs[i].values())[0]\n",
    "        scores_test[i].add(test_dqn(env_i, agent))\n",
    "            \n",
    "            \n",
    "def test_dqn(env, agent = None, n_episodes=10, max_t=1000):\n",
    "    _scores = 0                       \n",
    "    for i_episode in range(1, n_episodes+1):\n",
    "        _state = env.reset()\n",
    "        _score = 0\n",
    "        for t in range(max_t):\n",
    "            _action = agent.act(_state, 0.0)\n",
    "            _next_state, _reward, _done, _ = env.step(_action)\n",
    "            _state = _next_state\n",
    "            _score += _reward\n",
    "            if _done:\n",
    "                break \n",
    "        _scores +=  _score              \n",
    "    return _scores/n_episodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params: (Seed, Length, Gravity, Force_mag)\n",
      "------------ Task n°1/4 ------------\n",
      "Current param: (0, 1, 9.8, 10.0)\n",
      "Episode 100\tAverage Score: 25.00\n",
      "Episode 200\tAverage Score: 20.80\n",
      "Episode 300\tAverage Score: 15.74\n",
      "Episode 400\tAverage Score: 16.55\n",
      "Episode 500\tAverage Score: 15.36\n",
      "Episode 600\tAverage Score: 14.03\n",
      "Episode 700\tAverage Score: 16.69\n",
      "Episode 800\tAverage Score: 19.23\n",
      "Episode 900\tAverage Score: 43.70\n",
      "Episode 1000\tAverage Score: 167.24\n",
      "Episode 1006\tAverage Score: 203.86\n",
      "Environment solved in 906 episodes!\tAverage Score: 203.86\n",
      "[451.08500000000004]\n",
      "------------ Task n°2/4 ------------\n",
      "Current param: (0, 1, 2, 10.0)\n",
      "Episode 100\tAverage Score: 81.32\n",
      "Episode 145\tAverage Score: 202.39\n",
      "Environment solved in 45 episodes!\tAverage Score: 202.39\n",
      "[331.05499999999995, 501.075]\n",
      "------------ Task n°3/4 ------------\n",
      "Current param: (0, 10, 9.8, 10.0)\n",
      "Episode 100\tAverage Score: 117.17\n",
      "Episode 200\tAverage Score: 128.48\n",
      "Episode 300\tAverage Score: 155.07\n",
      "Episode 400\tAverage Score: 175.21\n",
      "Episode 500\tAverage Score: 182.07\n",
      "Episode 600\tAverage Score: 152.80\n",
      "Episode 700\tAverage Score: 159.65\n",
      "Episode 796\tAverage Score: 201.13\n",
      "Environment solved in 696 episodes!\tAverage Score: 201.13\n",
      "[360.80499999999995, 674.15, 262.54]\n",
      "------------ Task n°4/4 ------------\n",
      "Current param: (0, 10, 2, 10.0)\n",
      "Episode 51\tAverage Score: 201.18\n",
      "Environment solved in -49 episodes!\tAverage Score: 201.18\n",
      "[149.14000000000001, 308.095, 201.57500000000005, 372.56000000000006]\n"
     ]
    }
   ],
   "source": [
    "params = {\"length\": [1, 10], \n",
    "         \"gravity\": [9.8, 2]}\n",
    "\n",
    "print(\"Params: (Seed, Length, Gravity, Force_mag)\")\n",
    "agent = Q_learner(state_size=4, action_size=2, seed=0, hiddens = [100,100], args = args)\n",
    "seed = 0\n",
    "\n",
    "task_wrapper = Task_Wrapper(env_name,params)\n",
    "scores = dict()\n",
    "test_scores = dict()\n",
    "for task_id in range(len(task_wrapper.params)):\n",
    "    print(\"------------ Task n°{}/{} ------------\".format(task_id+1,len(task_wrapper.params) ))\n",
    "    envs = task_wrapper.next_task()\n",
    "    param_tuple = list(envs[-1].keys())[0]\n",
    "    print(\"Current param: {}\".format(param_tuple))\n",
    "    scores[param_tuple], test_scores[param_tuple] = dqn(envs, agent)\n",
    "    print(test_scores[param_tuple])\n",
    "    #test_scores_i = dict()\n",
    "    #print(\"current:{}\".format(task_wrapper.current_param))\n",
    "    #for i in range(task_wrapper.current_param):\n",
    "    #    score_test_i = np.array(test_dqn(task_wrapper.get_env(i), agent))\n",
    "    #    score_test_i_mean = score_test_i.mean()\n",
    "    #    test_scores_i[transform_dict_to_tuple(task_wrapper.params[i])] = score_test_i_mean\n",
    "    #test_scores.append(test_scores_i)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{(0, 1, 9.8, 10.0): [451.08500000000004], (0, 1, 2, 10.0): [331.05499999999995, 501.075], (0, 10, 9.8, 10.0): [360.80499999999995, 674.15, 262.54], (0, 10, 2, 10.0): [149.14000000000001, 308.095, 201.57500000000005, 372.56000000000006]}\n"
     ]
    }
   ],
   "source": [
    "print(test_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Save params</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'length': 1, 'gravity': 9.8}, {'length': 1, 'gravity': 2}, {'length': 10, 'gravity': 9.8}, {'length': 10, 'gravity': 2}]\n",
      "dict_keys([(0, 1, 9.8, 10.0), (0, 1, 2, 10.0), (0, 10, 9.8, 10.0), (0, 10, 2, 10.0)])\n"
     ]
    }
   ],
   "source": [
    "print(task_wrapper.params)\n",
    "print(scores.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "columns = [\"Task#\",\"Seed\", \"Gravity\", \"Length\", \"Force_mag\", \"Episode\", \"Score\"]\n",
    "df = pd.DataFrame(columns = columns)\n",
    "for j,param in enumerate(list(scores.keys())):\n",
    "    print(j)\n",
    "    values = scores[param]\n",
    "    liste = []\n",
    "\n",
    "    for i in range(len(values)):\n",
    "        liste.append([j, param[0], param[1], param[2],param[3], i, values[i]])\n",
    "    df2 = pd.DataFrame(data = liste, columns = columns)\n",
    "    df = pd.concat([df,df2])\n",
    "    df.reset_index()\n",
    "path= \"results/length_gravity_v0.csv\"\n",
    "df.to_csv(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "-1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-915ca3650c39>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mscore_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_scores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtest_score\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_scores\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mscore_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_score\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: -1"
     ]
    }
   ],
   "source": [
    "score_list = [np.array(list(test_scores[-1].keys()))]\n",
    "for test_score in test_scores:\n",
    "    score_list.append(np.array(list(test_score.values())))\n",
    "scores= np.array(score_list)\n",
    "print(scores)\n",
    "path= \"results/force_mag_v0.npy\"\n",
    "np.save(path, scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "offset = 0\n",
    "plt.clf()\n",
    "\n",
    "fig , ax = plt.subplots(1, len(params), figsize=(20,10))\n",
    "#concatenated_score = []\n",
    "#concatenated_index = []\n",
    "for task_id, score in enumerate(scores):\n",
    "    #concatenated_score += score\n",
    "    #concatenated_index += list(np.array([i for i in range(len(score))]) + offset)\n",
    "    episode = np.array([i for i in range(len(score))])\n",
    "    offseted_episode = list(episode + offset)\n",
    "    ax[task_id].plot(episode, score)\n",
    "    offset += len(score)\n",
    "    ax[task_id].set_ylim([0,300])\n",
    "    ax[task_id].set_title(\"Task n°{} (Length: {})\".format(task_id, params[task_id]))\n",
    "ax[0].set_ylabel(\"Score\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
